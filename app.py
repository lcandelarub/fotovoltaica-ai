import streamlit as st
import PyPDF2
import os
import json
from openai import OpenAI

# --- CONFIGURAR LA API KEY DESDE SECRETS ---
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("‚ùå ERROR: No se encontr√≥ la API Key de OpenAI. Config√∫rala en Streamlit Secrets.")
    st.stop()

client = OpenAI(api_key=api_key)

# --- CONFIGURAR ARCHIVO DE MEMORIA ---
knowledge_file = "knowledge.json"
if not os.path.exists(knowledge_file):
    with open(knowledge_file, "w") as f:
        json.dump({}, f)

# --- INTERFAZ DE LA APP ---
st.title("üîÜ Chat de Fotovoltaica AI (Solo responde con documentos)")
st.write("Haz preguntas y obt√©n respuestas basadas √∫nicamente en los documentos que has subido.")

# --- SUBIR DOCUMENTOS Y GUARDAR SU CONTENIDO ---
st.sidebar.header("üìÇ Subir nuevos documentos")
uploaded_files = st.sidebar.file_uploader("Sube PDFs para a√±adir conocimiento", accept_multiple_files=True, type="pdf")

def process_and_store_documents(files):
    with open(knowledge_file, "r") as f:
        knowledge = json.load(f)

    for file in files:
        text = extract_text_from_pdf(file)
        knowledge[file.name] = text

    with open(knowledge_file, "w") as f:
        json.dump(knowledge, f, indent=4)

    st.sidebar.success("üìö Documentos a√±adidos al conocimiento de la IA.")

def extract_text_from_pdf(pdf_file):
    text = ""
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    for page in pdf_reader.pages:
        text += page.extract_text() + "\n"
    return text

if uploaded_files:
    process_and_store_documents(uploaded_files)

# --- INTERFAZ DE PREGUNTAS ---
query = st.text_input("üîç Escribe tu pregunta sobre fotovoltaica:")
if query:
    with open(knowledge_file, "r") as f:
        knowledge = json.load(f)

    if not knowledge:
        st.warning("‚ö†Ô∏è No hay documentos cargados. Por favor, sube documentos antes de hacer preguntas.")
    else:
        combined_text = "\n\n".join(knowledge.values())

        prompt = f""" 
        Basado en la siguiente informaci√≥n obtenida exclusivamente de los documentos proporcionados,
        responde la pregunta de forma clara y estructurada. 

        Si la informaci√≥n no est√° en los documentos, responde con: "No lo s√©".

        Pregunta: {query}

        Informaci√≥n disponible:
        {combined_text[:2000]}

        Respuesta:
        """

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Eres un asistente t√©cnico en energ√≠a solar fotovoltaica y solo respondes con la informaci√≥n proporcionada en los documentos."},
                    {"role": "user", "content": prompt}
                ]
            )

            generated_response = response.choices[0].message.content

            # Verificar si la respuesta generada contiene informaci√≥n o si debe responder "No lo s√©"
            if "No lo s√©" in generated_response or len(generated_response.strip()) < 10:
                st.warning("ü§î La informaci√≥n no est√° en los documentos. Respuesta: 'No lo s√©'.")
            else:
                st.subheader("üí° Respuesta generada por IA:")
                st.write(generated_response)

        except Exception as e:
            st.error(f"‚ùå ERROR inesperado: {str(e)}")

